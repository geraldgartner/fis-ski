{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "import unicodecsv\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests_cache\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "requests_cache.install_cache('demo_cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "s.mount('http://', requests.adapters.HTTPAdapter(max_retries=10))\n",
    "\n",
    "def read_lines(reader):\n",
    "    headers = reader.next()\n",
    "    for x in reader:\n",
    "        yield dict(zip(headers,x))\n",
    "    \n",
    "def stringify_children(node, down=False):\n",
    "    from lxml.etree import tostring\n",
    "    from itertools import chain\n",
    "    parts = ([node.text if hasattr(node, 'text') else node] +\n",
    "            (list(chain(*([c.text if hasattr(c,'text') else c] + \n",
    "                          ([tostring(c,method=\"text\",encoding=\"unicode\")] if down and hasattr(c,'text') and not c.text else []) +\n",
    "                          [c.tail if hasattr(c,'tail') else ''] for c in node.getchildren())))\n",
    "             if hasattr(node, 'getchildren') else []) +\n",
    "            [node.tail if hasattr(node, 'tail') else ''])\n",
    "    # filter removes possible Nones in texts and tails\n",
    "    return ''.join(filter(None, parts))\n",
    "    \n",
    "def extract_data(x,down=False):\n",
    "    return stringify_children(x,down=down).strip()\n",
    "\n",
    "def extract_line(tr):\n",
    "    return [x\n",
    "            for x in \n",
    "            tr.xpath('./*[name()=\"th\" or name()=\"td\"]')]\n",
    "\n",
    "\n",
    "def extract_table(t):\n",
    "    trs = t.xpath('.//tr')\n",
    "    headers = [extract_data(x) for x in extract_line(trs[0])]\n",
    "    ds = []\n",
    "    for tr in trs[1:]:\n",
    "         ds.append(dict(zip(headers,extract_line(tr))))\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_url = 'https://data.fis-ski.com/global-links/all-fis-results.html?place_search=&seasoncode_search=all&sector_search=AL&date_search=&gender_search=&category_search=WSC&codex_search=&nation_search=&disciplinecode_search=&date_from=01&search=Search&limit=100'\n",
    "\n",
    "root1 = lh.fromstring(s.get(root_url).content)\n",
    "table = root1.xpath('//div[contains(@class,\"bloc-tab\")]/table[contains(@class,\"footable\")]')[0]\n",
    "\n",
    "events = [x for x in extract_table(table) if len(x.keys())>1]\n",
    "for event in events:\n",
    "    keys = event.keys()\n",
    "    #print(keys)\n",
    "    event['link'] = event['Event'].xpath('.//a/@href')[0]\n",
    "    for k in keys:\n",
    "        event[k] = extract_data(event[k],down=True)\n",
    "    #print(event['Place'])\n",
    "    #print(event['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_url = 'https://data.fis-ski.com/global-links/all-fis-results.html?place_search=&seasoncode_search=all&sector_search=AL&date_search=&gender_search=&category_search=WSC&codex_search=&nation_search=&disciplinecode_search=&date_from=01&search=Search&limit=100'\n",
    "\n",
    "root1 = lh.fromstring(s.get(root_url).content)\n",
    "table = root1.xpath('//div[contains(@class,\"bloc-tab\")]/table[contains(@class,\"footable\")]')[0]\n",
    "\n",
    "events = [x for x in extract_table(table) if len(x.keys())>1]\n",
    "for event in events:\n",
    "    keys = event.keys()\n",
    "    event['link'] = event['Event'].xpath('.//a/@href')[0]\n",
    "    for k in keys:\n",
    "        event[k] = extract_data(event[k],down=True)\n",
    "    #print(event['Place'])\n",
    "    #print(event['link'])\n",
    "    root2 = lh.fromstring(s.get(event['link']).content)\n",
    "    table = root2.xpath('//div[contains(@class,\"bloc-tab\")]/table[contains(@class,\"footable\")]')[0]\n",
    "    subevents = [x for x in extract_table(table) if 'Discipline' in x.keys()]\n",
    "    for se in subevents:\n",
    "        keys = se.keys()\n",
    "        try:\n",
    "            se['url'] = se['Discipline'].xpath('.//a/@href')[0]\n",
    "            #print '    ', se['url']\n",
    "        except IndexError:\n",
    "            #print 'not found', se.keys(), lh.tostring(se['Discipline']), event['link']\n",
    "            #print '   ', se.keys()\n",
    "            pass\n",
    "            #print 'could not find link'\n",
    "        for k in keys:\n",
    "            if k!='url':\n",
    "                se[k] = extract_data(se[k],down=True)\n",
    "        for k in event.keys():\n",
    "            se['event_%s' % k] = event[k]\n",
    "    event['subevents'] = subevents\n",
    "    \n",
    "all_subevents = list(itertools.chain(*[event['subevents'] for event in events]))\n",
    "#print len(all_subevents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': '',\n",
       " 'Category': 'WSC',\n",
       " 'Codex': '0210',\n",
       " 'Comments': '',\n",
       " 'Date': u'08.02.2017',\n",
       " 'Discipline': 'Super G',\n",
       " 'Download': u'Results (761.32 kb)Results, Analysis, Standings (7.82 MB)Start List (703.82 kb)',\n",
       " 'Gender': u'M',\n",
       " 'Nation': u'SUI',\n",
       " 'Place': u'St. MoritzRUNCETLOCSTATUSRun 112:0012:00Official result',\n",
       " 'event_CategoryCat.': 'TRA',\n",
       " 'event_Codex': '',\n",
       " 'event_Comments': 'Check changes',\n",
       " 'event_Date': '6.-19.2.2017',\n",
       " 'event_Discipline': '12xDH - 4xSL - 4xGS - SG - AC',\n",
       " 'event_Download': '',\n",
       " 'event_Event': '',\n",
       " 'event_GenderG.': u'L                                    M',\n",
       " 'event_NationNat.': u'SUI',\n",
       " 'event_Place': 'St. Moritz',\n",
       " 'event_SectorSect.': 'AL',\n",
       " 'event_Status': u'',\n",
       " 'event_link': 'https://data.fis-ski.com/dynamic/event-details.html?event_id=39153&cal_suchsector=AL',\n",
       " 'url': 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=86878'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subevents[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71020',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71022',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71021',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71024',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71023',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71026',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71027',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71025',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71029',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=74601',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71028',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71031',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71030',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71033',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71032',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71034',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71036',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71035',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71037',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71039',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71038',\n",
       " 'https://data.fis-ski.com/dynamic/results.html?sector=AL&raceid=71040']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['url'] for x in events[2]['subevents'] if 'url' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "done_urls = []\n",
    "all_data = []\n",
    "\n",
    "\n",
    "if True: #with open('/media/sf_ddj/geschichten/2016-10-26-zeit-SpA/skilaeufer/refined/subpages.csv') as f:\n",
    "    l = all_subevents\n",
    "    for i,x in enumerate(l):\n",
    "        if not 'url' in x:\n",
    "            continue\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        if x['url'] in done_urls:\n",
    "            continue\n",
    "        rq = s.get(x['url'])\n",
    "        if rq.status_code!=200:\n",
    "            print(x['url'])\n",
    "            print(rq)\n",
    "            continue\n",
    "        #print(x['url'])\n",
    "        root = lh.fromstring(rq.content)\n",
    "        tables = root.xpath('//div[contains(@class,\"bloc-tab\")]/table[contains(@class,\"footable\")]')\n",
    "        if len(tables)!=1:\n",
    "            print('too many tables', x['url'], tables)\n",
    "            continue\n",
    "        \n",
    "        tbl = tables[0]\n",
    "        for d in extract_table(tbl):\n",
    "            for k in d:\n",
    "                #print k\n",
    "                d[k] = extract_data(d[k],down=True)\n",
    "                \n",
    "             #d = dict(zip(headers,extract_data(tr)))\n",
    "            d['source_url']=x['url']\n",
    "            for k in x.keys():\n",
    "                d['subevent_%s' % k] = x[k]\n",
    "            all_data.append(d)\n",
    "        done_urls.append(x['url'])\n",
    "        \n",
    "        if i%100==0:\n",
    "            with open('done_urls_2.json','w') as f2:\n",
    "                json.dump(done_urls, f2)\n",
    "\n",
    "            with open('all_data_2.json','w') as f2:\n",
    "                json.dump(all_data, f2)\n",
    "                \n",
    "with open('done_urls.json','w') as f2:\n",
    "    json.dump(done_urls, f2)\n",
    "\n",
    "with open('all_data.json','w') as f2:\n",
    "    json.dump(all_data, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_keys = set()\n",
    "for x in all_data:\n",
    "    for k in x.keys():\n",
    "        all_keys.add(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_keys = sorted(list(all_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[x.get(k,'?????') for k in all_keys] for x in all_data], columns=all_keys)\n",
    "#with open('fin_output_2.csv','w') as of:\n",
    "#    ow = unicodecsv.writer(of)\n",
    "#    ow.writerow(all_keys)\n",
    "#    for x in all_data:\n",
    "#        ow.writerow()\n",
    "df.to_csv('fin_output_2.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('success', datetime.datetime(2017, 2, 15, 15, 49, 10, 363893))\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print('success',datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
